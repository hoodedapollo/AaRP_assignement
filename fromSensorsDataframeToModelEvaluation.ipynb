{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fromSensorsDataframeToModelEvaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoodedapollo/AaRP_assignement/blob/master/fromSensorsDataframeToModelEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u28U9u8ImsMm",
        "colab_type": "text"
      },
      "source": [
        "#Obtain Sensor Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkkHUI6Kf2Y_",
        "colab_type": "text"
      },
      "source": [
        "## Read Sensor Dataframe form File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufLpP2c3kXkv",
        "colab_type": "code",
        "outputId": "0f5e2975-035d-46a3-8fc8-f11a58417dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "!mkdir /content/dataframes\n",
        "\n",
        "download = drive.CreateFile({'id': '1_ioXezgNztjZyGzLownSh4ATQh6YCMW4'}) # https://drive.google.com/file/d/1_ioXezgNztjZyGzLownSh4ATQh6YCMW4/view?usp=sharing\n",
        "download.GetContentFile('/content/dataframes/IMUSsensors.csv')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "IMUsensorsDataFrame = pd.read_csv('/content/dataframes/IMUSsensors.csv', header = [0,1], index_col = [0,1,2])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/dataframes’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9hiEl85tm69",
        "colab_type": "text"
      },
      "source": [
        "## Fill NaNs with zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoERN6kStYuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMUsensorsDataFrame = IMUsensorsDataFrame.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYnCozbpusV_",
        "colab_type": "text"
      },
      "source": [
        "## Build one sensorDataframe for each sensor (IMU)\n",
        "\n",
        "* 6 columns for data (accX, accY, accZ, gyroX, gyroY, gyroZ) \n",
        "* 4 columns for labels (locomotion, low level left arm, low level right arm, medium level both arms = gestures)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sySjv2OZIn5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def singleSensorDataframe(multipleSensorsDataframe, sensorName):\n",
        "  return IMUsensorsDataFrame[[sensorName,'labels']]\n",
        "\n",
        "backImuDataframe =  singleSensorDataframe(IMUsensorsDataFrame, 'backImu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpxvuLN2yYdA",
        "colab_type": "text"
      },
      "source": [
        "# Useful Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLRo1jOeC0l3",
        "colab_type": "text"
      },
      "source": [
        "##Find single label sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdNTLN6qqvvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLabelSequence(object):\n",
        "  def __init__(self,sequence):\n",
        "    self.sequence = sequence\n",
        "    self.indecesWhereSequenceChanges = None\n",
        "    self.rangesWhereSequencesChanges = None\n",
        "    self.indeces = None\n",
        "    self.labels = None\n",
        "    self.slices = None\n",
        "    \n",
        "    self.findIndecesWhereSequenceChanges()\n",
        "    self.findRangesWhereSequencesChanges()\n",
        "\n",
        "  \n",
        "  def findIndecesWhereSequenceChanges(self):\n",
        "    sequenceChange = np.array(self.sequence[:-1]) != np.array(self.sequence[1:])\n",
        "    sequenceChange = np.append(sequenceChange, True)\n",
        "    self.indecesWhereSequenceChanges = np.array(range(len(sequenceChange)))[sequenceChange]\n",
        "\n",
        "  \n",
        "  def findRangesWhereSequencesChanges(self):\n",
        "    self.rangesWhereSequencesChanges = [0] + list(self.indecesWhereSequenceChanges + 1)\n",
        "\n",
        "  \n",
        "  def  getLabelsAndRangesLists(self):\n",
        "    numberOfDifferentSequences = len(self.rangesWhereSequencesChanges) - 1\n",
        "    \n",
        "    self.ranges = []\n",
        "    self.labels = [] \n",
        "    for i in range(numberOfDifferentSequences):\n",
        "      if self.sequence[self.rangesWhereSequencesChanges[i]] != 0:\n",
        "        self.ranges.append([self.rangesWhereSequencesChanges[i], self.rangesWhereSequencesChanges[i+1]])\n",
        "        self.labels.append(self.sequence[self.rangesWhereSequencesChanges[i]])\n",
        "    \n",
        "    return self.ranges,  self.labels\n",
        "    \n",
        "  \n",
        "  def getRangesWithLabel(self, label):\n",
        "    numberOfDifferentSequences = len(self.rangesWhereSequencesChanges) - 1\n",
        "    \n",
        "    ranges = []\n",
        "    for i in range(numberOfDifferentSequences):\n",
        "      if self.sequence[self.rangesWhereSequencesChanges[i]] == label:\n",
        "        ranges.append([self.rangesWhereSequencesChanges[i], self.rangesWhereSequencesChanges[i+1]])\n",
        "        \n",
        "    return ranges  \n",
        "    \n",
        "  \n",
        "  def getLabelsAndSlicesLists(self):\n",
        "    numberOfDifferentSequences = len(self.rangesWhereSequencesChanges) - 1\n",
        "    \n",
        "    self.slices = []\n",
        "    self.labels = [] \n",
        "    for i in range(numberOfDifferentSequences):\n",
        "      if self.sequence[self.rangesWhereSequencesChanges[i]] != 0:\n",
        "        self.slices.append(slice(self.rangesWhereSequencesChanges[i], self.rangesWhereSequencesChanges[i+1]))\n",
        "        self.labels.append(self.sequence[self.rangesWhereSequencesChanges[i]])\n",
        "    \n",
        "    return self.slices,  self.labels\n",
        "    \n",
        "  \n",
        "  def getSlicesWithLabel(self, label):\n",
        "    numberOfDifferentSequences = len(self.rangesWhereSequencesChanges) - 1\n",
        "    \n",
        "    slices = []\n",
        "    for i in range(numberOfDifferentSequences):\n",
        "      if self.sequence[self.rangesWhereSequencesChanges[i]] == label:\n",
        "        slices.append(slice(self.rangesWhereSequencesChanges[i], self.rangesWhereSequencesChanges[i+1]))\n",
        "        \n",
        "    return slices\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odv8EhGVpDL5",
        "colab_type": "text"
      },
      "source": [
        "## Timeseries Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILF8O5xSoN0h",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Timeseries(object):\n",
        "  def __init__(self, dataframe, tsSlices):\n",
        "    self.items = []\n",
        "    for tsSlice in tsSlices:\n",
        "      self.items.append(dataframe.iloc[tsSlice,:6])\n",
        "  \n",
        "  def getConcatenatedDf(self):\n",
        "    return pd.concat(self.items)\n",
        "  \n",
        "  def getTimeseries(self):\n",
        "    return self.items\n",
        "  \n",
        "  def plotWithIndexAndChannels(self, tsIndex, channelColumns = None):\n",
        "    sensorValues = self.items[tsIndex].values\n",
        "    time = range(len(sensorValues))\n",
        "    \n",
        "    if not channelColumns: \n",
        "      channelColumns = range(sensorValues.shape[-1])\n",
        "       \n",
        "    for i in channelColumns:\n",
        "      plt.plot(time,  sensorValues[:,i], label='sensor column: {0}'.format(i))\n",
        "    \n",
        "    plt.title('Timeseries')\n",
        "    plt.xlabel('Sample index')\n",
        "    plt.ylabel('Sensordata values')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7KxhO3Ksc2b",
        "colab_type": "text"
      },
      "source": [
        "## From TimeSeries Instance To Train Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE4E5XXruG5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TensorNNready(object):\n",
        "  def __init__(self, timeseries, lookback = 40, delay = 1):\n",
        "    self.timeseries = timeseries\n",
        "    self.lookback = lookback\n",
        "    self.delay = delay\n",
        "  \n",
        "  def setTimeseries(self, timeseries):\n",
        "    self.timeseries = timeseries\n",
        "  \n",
        "  def setLookback(self, lookback):\n",
        "    self.lookback = lookback\n",
        "  \n",
        "  def setDelay(self, delay):\n",
        "    self.delay = delay\n",
        "\n",
        "  def samplesTargets(self, multivariateTimeseries, min_index=0, step=1):\n",
        "      max_index = len(multivariateTimeseries) - self.delay - 1 # -1 is because indexes start at 0\n",
        "      currentTimestep = min_index + self.lookback\n",
        "\n",
        "      rows = np.arange(currentTimestep, max_index)\n",
        "\n",
        "      samples = np.zeros((len(rows), self.lookback // step, multivariateTimeseries.shape[-1]))   # (samples, timesteps, features)\n",
        "      targets = np.zeros((len(rows), multivariateTimeseries.shape[-1]))\n",
        "\n",
        "      for j, row in enumerate(rows):\n",
        "        indices = range(rows[j] - self.lookback, rows[j], step)   # rows starts at i (see line 12), which is at minimum i = min_index + lookback (see line 5) \n",
        "                                                               # and at each loop it is increased by the length of the batches or the remaining \n",
        "                                                               # length to the max_index (see line13)  \n",
        "        samples[j] = multivariateTimeseries[indices]                           # data[indices] is all the timesteps starting lookback number of steps back from current timestep j to current time step j (sampled at step frquency)\n",
        "        targets[j] = multivariateTimeseries[rows[j] + self.delay]  \n",
        "\n",
        "      return samples, targets \n",
        "\n",
        "\n",
        "  def allSamplesTargets(self, min_index=0, step=1):\n",
        "      for i, self.ts in enumerate(self.timeseries.items):\n",
        "        if i == 0:\n",
        "          samples, targets = self.samplesTargets(self.ts.values, min_index, step)\n",
        "        else:\n",
        "          partial_samples, partial_targets = self.samplesTargets(self.ts.values, min_index, step)\n",
        "          samples = np.concatenate((samples, partial_samples), axis = 0)  \n",
        "          targets = np.concatenate((targets, partial_targets), axis = 0)  \n",
        "\n",
        "      return samples, targets "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBs5Z56uJQzc",
        "colab_type": "text"
      },
      "source": [
        "## define and train the NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIrl1Balb8yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# abstarct class\n",
        "class NNModel(ABC):\n",
        "  def __init__(self, trainSamples = None, trainTargets = None):\n",
        "    self.trainSamples = trainSamples\n",
        "    self.trainTargets = trainTargets\n",
        "  \n",
        "  def defineModel(self): \n",
        "      pass\n",
        "\n",
        "  def setFilepath(self, modelFilepath):\n",
        "    self.callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "          monitor='val_loss',\n",
        "          patience=3,\n",
        "        ),\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "          filepath=modelFilepath,\n",
        "          monitor='val_loss',\n",
        "          save_best_only=True,\n",
        "         )\n",
        "     ]\n",
        "\n",
        "  def compileModel(self, modelOptimizer = 'adam', modelLoss = 'mse'):\n",
        "    self.model.compile(optimizer=modelOptimizer, loss=modelLoss)\n",
        "\n",
        "  def fitModel(self, modelEpochs = 30, modelBatchSize = 128 ):\n",
        "    self.history = self.model.fit( self.trainSamples,   self.trainTargets,\n",
        "                                shuffle=True,\n",
        "                                epochs=modelEpochs,\n",
        "                                batch_size=modelBatchSize,\n",
        "                                callbacks=self.callbacks_list,\n",
        "                                validation_split=0.2)\n",
        "  \n",
        "  def loadFromFilepath(self, modelFilepath):\n",
        "    self.model = keras.models.load_model(modelFilepath)\n",
        "\n",
        "    \n",
        "    \n",
        "class baseLSTMModel(NNModel): \n",
        "  \n",
        "  # overriding abstract method \n",
        "  def defineModel(self, modelRecurrentDropout = 0.5): \n",
        "      input_tensor = Input(shape=(None, self.trainSamples.shape[-1]))\n",
        "      x = layers.LSTM(32, recurrent_dropout=modelRecurrentDropout)(input_tensor)\n",
        "      output_tensor = layers.Dense(self.trainSamples.shape[-1])(x)\n",
        "\n",
        "      self.model = Model(input_tensor, output_tensor)\n",
        "      self.model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGfQAXWm0cW",
        "colab_type": "text"
      },
      "source": [
        "## generate samples and targets given sensor dataframe, activity category and name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_kXvsM6m5Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "class SamplesAndTargetsGenerator(object):\n",
        "  def __init__(self, sensorDf):\n",
        "    self.sensorDf = sensorDf\n",
        "   \n",
        "    self.activityDict = {  \n",
        "      'locomotion' : {\n",
        "          'nullActivity' : 0,\n",
        "          'stand'        : 1,\n",
        "          'walk'         : 2,\n",
        "          'sit'          : 3,\n",
        "          'lie'          : 4,\n",
        "      },\n",
        "    \n",
        "      'llRightArm' : {\n",
        "          'nullActivity' : 0,\n",
        "          'unlock'       : 401,\n",
        "          'stir'         : 402,\n",
        "          'lock'         : 403,\n",
        "          'close'        : 404,\n",
        "          'reach'        : 405,\n",
        "          'open'         : 406,\n",
        "          'sip'          : 407,\n",
        "          'clean'        : 408,\n",
        "          'bite'         : 409,\n",
        "          'cut'          : 410,\n",
        "          'spread'       : 411,\n",
        "          'release'      : 412,\n",
        "          'move'         : 413,\n",
        "      },\n",
        "    }\n",
        "    \n",
        "    self.lookback = 40\n",
        "    self.delay = 1\n",
        "  \n",
        "    self.trainDf = None\n",
        "    self.testDf = None\n",
        "    \n",
        "    self.normTrainDf = None\n",
        "    self.normTestDf = None\n",
        "    \n",
        "    self.trainMultiLabelSequence = None\n",
        "    \n",
        "  def trainTestSplitDataframe(self):\n",
        "    # The testing dataset is composed of data from subjects 2 and 3 (ADL4, ADL5).\n",
        "    idx = pd.IndexSlice\n",
        "\n",
        "    trainDf1 = self.sensorDf.loc[idx['S1':'S4', ('ADL1','ADL2','ADL3','Drill')], :]\n",
        "    trainDf2 = self.sensorDf.loc[idx[('S1','S4'), ('ADL4','ADL5')], :]\n",
        "    self.trainDf = pd.concat([trainDf1,trainDf2])\n",
        "    \n",
        "    self.testDf = self.sensorDf.loc[idx[('S2','S3'), ('ADL4','ADL5')], :]\n",
        "  \n",
        "  def normalizeTrainDataframe(self):\n",
        "    normDf = self.trainDf.iloc[:,:6]   # select only the sensor columns\n",
        "    normDf = (normDf-normDf.min())/(normDf.max()-normDf.min())\n",
        "    self.normTrainDf = pd.concat([normDf, self.trainDf.iloc[:,-4:]], axis = 1)   # concatenate the label columns\n",
        "\n",
        "\n",
        "  def normalizeTestDataframe(self):\n",
        "    teDf = self.testDf.iloc[:,:6]   # select only the sensor columns\n",
        "    trDf = self.trainDf.iloc[:,:6]\n",
        "    normDf = (teDf-trDf.min())/(trDf.max()-trDf.min())   \n",
        "    self.normTestDf = pd.concat([normDf, self.testDf.iloc[:,-4:]], axis = 1)   # concatenate the label columns\n",
        "\n",
        "  def getTrainSamplesAndTargets(self, activityCategory, activityName):\n",
        "    #0. set activity catgeory category \n",
        "    trainMultiLabelSequence = MultiLabelSequence(self.normTrainDf['labels',activityCategory].values)\n",
        "    \n",
        "    #1.find single label sequence\n",
        "    activityId = self.activityDict[activityCategory][activityName]\n",
        "    trainSlices = trainMultiLabelSequence.getSlicesWithLabel(activityId)\n",
        "  \n",
        "    #2.create time series\n",
        "    trainTimeseries = Timeseries(self.normTrainDf, trainSlices)\n",
        "    \n",
        "    #3.from timeseries instance to train tensor\n",
        "    trainTensorNNready = TensorNNready(trainTimeseries, lookback = self.lookback, delay = self.delay)    \n",
        "    start = time.time()\n",
        "    trainSamples, trainTargets = trainTensorNNready.allSamplesTargets()\n",
        "    end = time.time()\n",
        "    print(\"Time required to compute samples and target tensors from timeseries: {0}\".format(end - start))\n",
        "    \n",
        "    return trainSamples, trainTargets\n",
        "  \n",
        "  def getTestSamplesAndTargets(self, activityCategory, activityName):\n",
        "    #0. set activity catgeory category \n",
        "    testMultiLabelSequence = MultiLabelSequence(self.normTestDf['labels',activityCategory].values)\n",
        "    \n",
        "    #1.find single label sequence\n",
        "    activityId = self.activityDict[activityCategory][activityName]\n",
        "    testSlices = testMultiLabelSequence.getSlicesWithLabel(activityId)\n",
        "    \n",
        "    #2.create time series\n",
        "    testTimeseries = Timeseries(self.normTestDf, testSlices)\n",
        "    \n",
        "    #3.from timeseries instance to train tensor\n",
        "    testTensorNNready = TensorNNready(testTimeseries, lookback = self.lookback, delay = self.delay)    \n",
        "    start = time.time()\n",
        "    testSamples, testTargets = testTensorNNready.allSamplesTargets()\n",
        "    end = time.time()\n",
        "    print(\"Time required to compute samples and target tensors from timeseries: {0}\".format(end - start))\n",
        "    \n",
        "    return testSamples, testTargets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nvs5Q493Jio",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcqHjxec3LWc",
        "colab_type": "text"
      },
      "source": [
        "## generate samples and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPr-AqR2F3JP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c9b30205-bf45-4dd1-e62b-a8cd2e8c2d8a"
      },
      "source": [
        "backImuGenerator = SamplesAndTargetsGenerator(backImuDataframe)\n",
        "backImuGenerator.trainTestSplitDataframe()\n",
        "\n",
        "backImuGenerator.normalizeTrainDataframe()\n",
        "trainWalkBackImuSamples, trainWalkBackImuTargets = backImuGenerator.getTrainSamplesAndTargets('locomotion', 'walk')\n",
        "\n",
        "backImuGenerator.normalizeTestDataframe()\n",
        "testWalkBackImuSamples, testWalkBackImuTargets = backImuGenerator.getTestSamplesAndTargets('locomotion', 'walk')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time required to compute samples and target tensors from timeseries: 56.65997815132141\n",
            "Time required to compute samples and target tensors from timeseries: 1.3107879161834717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH9GLmxmqVnY",
        "colab_type": "text"
      },
      "source": [
        "## Train Specific Model Using Generated Samples and Targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MI-vr7thKg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "cd9a926a-a7d2-4657-8642-1ed0ec071e47"
      },
      "source": [
        "trainSamples = trainWalkBackImuSamples\n",
        "trainTargets = trainWalkBackImuTargets\n",
        "modelFilepath = 'my_model_walk.h5'\n",
        "modelRecurrentDropout = 0.5\n",
        "\n",
        "# create and train the model\n",
        "walkModel = baseLSTMModel(trainSamples = trainSamples,  trainTargets = trainTargets)\n",
        "walkModel.defineModel()\n",
        "walkModel.setFilepath(modelFilepath)\n",
        "walkModel.compileModel()\n",
        "walkModel.fitModel(modelEpochs = 2)\n",
        "\n",
        "# load and continue training the model\n",
        "walkModel.loadFromFilepath(modelFilepath)\n",
        "walkModel.fitModel(modelEpochs = 2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, None, 6)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                4992      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,190\n",
            "Trainable params: 5,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 87212 samples, validate on 21804 samples\n",
            "Epoch 1/2\n",
            "87212/87212 [==============================] - 41s 475us/step - loss: 0.0053 - val_loss: 0.0023\n",
            "Epoch 2/2\n",
            "87212/87212 [==============================] - 38s 436us/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Train on 87212 samples, validate on 21804 samples\n",
            "Epoch 1/2\n",
            "87212/87212 [==============================] - 40s 453us/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 2/2\n",
            "87212/87212 [==============================] - 37s 427us/step - loss: 0.0013 - val_loss: 0.0014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amJ2UTiHsENk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_IuyCXm8e3",
        "colab_type": "code",
        "outputId": "b22f21cd-214f-46cf-9af8-9248b9634282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "walkModel.model.evaluate(testWalkBackImuSamples, testWalkBackImuTargets)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18808/18808 [==============================] - 8s 441us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0010348577193664988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}